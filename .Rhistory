datawithrule <-applyRule(usedata,          #data
rule = rule.sinceany.cutoff,     #rule to apply
var.id = c("sample_measure"),    #variables with output of tests
cutoff = 0)                      #specific parameters for this rule.
## visualize data after applying rules ####
ggplot(data = datawithrule)+
geom_raster(aes(x = times,y = host_id, fill = factor(sir)))
ggplot(data = datawithrule)+
geom_path(aes(x = times,y = log10(as.numeric(sample_measure)+1), colour = factor(host_id)))+
theme(legend.position = "none")
unique(datawithrule$times)
unique(datawithrule$sample_measure)
unique(datawithrule$sir)
##arrange data for analysis ####
if(exists("data.arranged")) {rm(data.arranged)}
data.arranged <- arrangeData(data = usedata,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
covariates = c("ex_day"))
input = data.frame(data.arranged%>%
filter(i > 0 & s>0))
#fit the input data directly
fit.real <- glm(cbind(cases, s - cases) ~ 1 ,
family = binomial(link = "cloglog"),
offset = log(i/n)*dt,
data = input)
summary(fit.real)
#fit the analyseTransmission function
fit <- analyseTransmission(inputdata = usedata,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
preventError = TRUE)
#check
fit$coefficients ==fit.real$coefficients
fit$aic == fit.real$aic
fit$residuals == fit.real$residuals
#source the query function
source("src/R/Query.r")
#get data
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataC<- get.data("http://localhost:3030/datasetC")
#correct spelling
dataA <- rename(dataA,"inoculationStatus" = "innoculationStatus" )
dataB <- rename(dataB,"inoculationStatus" = "innoculationStatus" )
dataC <- rename(dataC,"inoculationStatus" = "innoculationStatus" )
#run analysis over each data set
localA <- analyseTransmission(inputdata = dataA,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "0")
localB<- analyseTransmission(inputdata = dataB,
rule = rule.sinceany.recode,
var.id = c("sample_result"),
method = "glm",
codesposnegmiss = c("+","-","NA"),
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "")
localC<- analyseTransmission(inputdata = dataC,
rule = rule.sinceany.cutoff,
var.id = c("sample_result"),
method = "glm",
cutoff = 0,
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "")
#perform meta-analysis
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/GlobalAlgorithm.R", echo=TRUE)
#perform meta-analysis
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
summary(metaana)
forest.meta(metaana)
funnel.meta(metaana,studlab=TRUE,contour = c(0.9, 0.95, 0.99))
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
combine.estimates
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/LocalAlgorithm.R", echo=TRUE)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataA
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
dataB<- get.data("http://localhost:3030/datasetB")
source("src/R/Query.r")                    #Query function
get.data
"http://localhost:3030/datasetA"
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
##use query to create data####
endpoint <- "http://localhost:3030/datasetA"
get.data <- function(endpoint){
sparql <- "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix : <http://www.semanticweb.org/trans_experiment#>
Prefix om: <http://www.ontology-of-units-of-measure.org/resource/om-2/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX tr: <http://www.thomsonreuters.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
SELECT ?round ?ex_day ?group ?level1 ?level2 ?level3 ?host_id ?treatment ?innoculationStatus ?sample_measure ?sample_result ?pathogen_name WHERE {
?experiment a :Experiment;
:experimentDay ?ex_day;
:hasMeasurement ?measurement.
optional {?experiment :repetition ?round;}
?measurement a :Measurement;
:hasHost ?host;
:hasSample ?sample.
?host :id ?host_id;
:treatment ?treatment;
:innoculationStatus ?innoculationStatus;
:locatedIn ?env.
?env  :groupNumber ?group.
optional{?env :level1 ?level1;}
optional{?env :level2 ?level2;}
optional{?env :level3 ?level3;}
optional{ ?measurement :experimentHour ?ex_hour. }
optional{ ?measurement
:hasQuantity ?quantity.
?quantity om:hasValue ?measure.
?measure om:hasNumericalValue ?sample_measure.
}
optional{ ?sample  :hasPathogen ?pathogen.
?pathogen :name ?pathogen_name }
optional {?sample :hasResult ?sample_result.}
} "
return(SPARQL(url = endpoint,query=sparql)$results)
}
#
#do data set 1
if(exists("usedata")){rm(usedata)};usedata<- get.data(endpoint)
view(usedata)
get.data <- function(endpoint){
sparql <- "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix : <http://www.semanticweb.org/trans_experiment#>
Prefix om: <http://www.ontology-of-units-of-measure.org/resource/om-2/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX tr: <http://www.thomsonreuters.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
SELECT ?round ?ex_day ?inoculationHour ?group ?level1 ?level2 ?level3 ?host_id ?treatment ?inoculationStatus ?sample_measure ?sample_result ?sample_type ?pathogen_name WHERE {
?experiment a :Experiment;
:experimentDay ?ex_day;
:hasMeasurement ?measurement.
optional {?experiment :repetition ?round;}
?measurement a :Measurement;
:hasHost ?host;
:hasSample ?sample.
?host :id ?host_id;
:treatment ?treatment;
:inoculationStatus ?inoculationStatus;
:locatedIn ?env.
?env  :groupNumber ?group.
optional{?experiment :hasInoculation ?inoculation.
?inoculation :involves ?host.
?inoculation	 :experimentHour ?inoculationHour.}
optional{?env :level1 ?level1.}
optional{?env :level2 ?level2;}
optional{?env :level3 ?level3;}
optional{ ?measurement :experimentHour ?ex_hour. }
optional{ ?measurement
:hasQuantity ?quantity.
?quantity om:hasValue ?measure.
?measure om:hasNumericalValue ?sample_measure.
}
?sample :hasType ?sample_type.
optional{?sample  :hasPathogen ?pathogen.
?pathogen :name ?pathogen_name }
optional {?sample :hasResult ?sample_result.}
}"
return(SPARQL(url = endpoint,query=sparql)$results)
}
usedata<- get.data(endpoint)
usedata
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataA
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/Query.R", echo=TRUE)
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/Query.R", echo=TRUE)
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
#run local algorithm for each data set ####
#run analysis over data set A
localA <- analyseTransmission(inputdata = dataA,           #data set
rule = rule.sinceany.cutoff, #rule to determine infection status
var.id = c("sample_measure"),#variable defining infection status
method = "glm",              #estimation method
cutoff = 0,                  #cutoff value for infection status
preventError = TRUE,         #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",        #co variants
reference = "control",       #reference category for multivariable estimation
control = "0")               #value of control treatment
#run analysis over data set B
localB<- analyseTransmission(inputdata = dataB,            #data set
rule = rule.sinceany.recode,  #rule to determine infection status
var.id = c("sample_result"),  #variable defining infection status
method = "glm",               #estimation method
codesposnegmiss = c("+","-","NA"), #values determining infection status pos, neg of missing
preventError = TRUE,          #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",         #co variants
reference = "control",        #reference category for multivariable estimation
control = "")                 #value of control treatment
localB
localA
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB,localC),
select.treatment = "control")
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/GlobalAlgorithm.R", echo=TRUE)
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
print(metaana)
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
#combine.estimates of glm's
combine.estimates.glm <- function(local.output,
select.treatment = "All"){
#get the means and standard errors
estimates = NULL;
for(i in c(1:length(local.output)))      {
estimates <- rbind(estimates,
cbind(data.frame(mean = summary(local.output[[i]])$coefficients[,1],
se  = summary(local.output[[i]])$coefficients[,2],
treatment = names(summary(local.output[[i]])$coefficients[,1])),
study = i))
}
if(select.treatment == "reference" | select.treatment == "control" )
estimates <- estimates%>%filter(treatment == "(Intercept)")
else if(treatment!= "All")
estimates <- estimates%>%filter(treatment == select.treatment)
#simply only use the intercepts
metaout<- metagen(TE =  estimates$mean,
seTE = estimates$se,
studlab = estimates$study,
subgroup = estimates$treatment,
fixed = FALSE)
return(metaout)
}
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
print(metaana)
forest.meta(metaana)
funnel.meta(metaana,studlab=TRUE,contour = c(0.9, 0.95, 0.99))
forest.meta(metaana)
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
dataB<- get.data("http://localhost:3030/datasetB")
dataB$sample_measure
dataB$sample_result
dataB$sample_measure
dataA$sample_measure
dataA$treatment
dataB$treatment
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/TutorialAlgorithms.R", echo=TRUE)
dataA
dataB
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
typeof(dataA$sample_measure)
#run local algorithm for each data set ####
#run analysis over data set A
localA <- analyseTransmission(inputdata = dataA,           #data set
rule = rule.sinceany.cutoff, #rule to determine infection status
var.id = c("sample_measure"),#variable defining infection status
method = "glm",              #estimation method
cutoff = 0,                  #cutoff value for infection status
preventError = TRUE,         #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",        #co variates
reference = "control",       #reference category for multivariable estimation
control = "0")               #value of control treatment
localA
localA
dataA
head(dataA)
dataA$sample_measure
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/LocalAlgorithm.R", echo=TRUE)
# perform analysis with default decisions ####
analyseTransmission<- function(inputdata,          #input data
rule = "sinceany",          #rule to determine whether sample is positive or negative
method ="glm", #estimation method
preventError = FALSE, #remove those entries with FOI = 0 but cases>1
){
#decide settings based on input data
# determine measure versus result choose for result if present
# determine the values to set for result or cut off for measure
# get value of reference group
#arrange data for analysis
data.arranged <- arrangeData(data = inputdata,
rule = rule,
var.id = var.id,
method = method,
covariates = covars,
...)
#remove those entries without susceptibles (contain no information and cause errors)
data.arranged <- data.arranged%>%filter(s>0)
data.arranged$treatment <- factor(data.arranged$treatment, ordered = FALSE)
data.arranged <- within(data.arranged, treatment <- relevel(treatment, ref = "control"))
#deal with potential error
if(preventError){data.arranged <- data.arranged%>%filter(i>0)}
#do analysis
#TO DO use covariates
fit <- switch(method,
glm = glm(#cbind(cases, s - cases) ~ treatment,
as.formula(paste("cbind(cases, s - cases) ~ ", paste(covars, collapse= "+"))),
family = binomial(link = "cloglog"),
offset = log(i/n)*dt,
data = data.arranged),
mll =stop("mle: not implemented yet"),#deal with number of levels in a maximum likelihood estimation.
finalsize = FinalSize,#is not yet implemented as well
stop("no other methods than glm or maximum likelihood")
)
#return outcome
return(fit)
}
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
#run local algorithm for each data set ####
#run analysis over data set A
localA <- analyseTransmission(inputdata = dataA,           #data set
rule = rule.sinceany.cutoff, #rule to determine infection status
var.id = c("sample_measure"),#variable defining infection status
method = "glm",              #estimation method
cutoff = 0,                  #cutoff value for infection status
preventError = TRUE,         #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",        #co variates
reference = "control",       #reference category for multivariable estimation
control = "0")               #value of control treatment
?tapply
### Laad Dataset_hypoallergene_hond.txt en analyseer de data.
# Gebruik read.table voor het importeren van data (zie hieronder)
# Inlezen kan ook via: Import Dataset . From CSV . kies bestand
# Dit commando bevat de argumenten header (kolomnamen) en sep
# (separator, scheidingsteken tussen waarden)
Dataset_hypoallergene_hond <- read.table("Dataset_hypoallergene_hond.txt", header=TRUE, sep="\t", stringsAsFactors=TRUE)
Dataset_hypoallergene_hond <- read.delim("C:/Surfdrive/Onderwijs/Cursorisch/WDH/20212022/WDH2_data/Dataset_hypoallergene_hond.txt")
View(Dataset_hypoallergene_hond)
## Toetsen van twee steekproefgemiddelden:
#	Laad Dataset_hypoallergene_hond.txt via Import dataset
# read.table() of Import Dataset . From CSV . kies bestand
# De omvang van het bestand (regels resp. kolommen)
dim(Dataset_hypoallergene_hond)
# Geef de namen van de variabelen
names(Dataset_hypoallergene_hond)
# geef de samenvattende statistiek voor alle variabelen
summary(Dataset_hypoallergene_hond)
# geef de gegevens van de eerste (6) records
head(Dataset_hypoallergene_hond)
# Open/activeer het data.frame object
attach(Dataset_hypoallergene_hond)
# maak een table van de variabele
table(Hypoallergene.hond, useNA = "ifany")
# bereken het gemiddelde log.hair.ug.g per groep Hypoallergene.hond
tapply(log.hair.ug.g, Hypoallergene.hond, mean, na.rm=TRUE)
# bereken de StDev log.hair.ug.g per groep hypoallergene.hond
?tapply # wat voor werking heeft de functie tapply?
tapply(log.hair.ug.g, Hypoallergene.hond, sd, na.rm=TRUE)
# maak een boxplot van log.hair.ug.g per groep Hypoallergene.hond
boxplot(log.hair.ug.g ~ Hypoallergene.hond, xlab = "Type hond", ylab = "log(Can f1-allergeen) in haar (ug/g)")
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=TRUE)
# maak een table van de variabele
table(Hypoallergene.hond, useNA = "no")
# maak een table van de variabele
table(Hypoallergene.hond, useNA = "always")
# maak een table van de variabele
table(Hypoallergene.hond, useNA = "ifany")
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=TRUE, paired =TRUE)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=TRUE, paired =F)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=F)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, var.equal=F)
# voer de t-toets voor onafhankelijke groepen uit
t.test( Hypoallergene,.hond,log.hair.ug.g  var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( Hypoallergene,hond,log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( Hypoallergene.hond,log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( y=Hypoallergene.hond,x=log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( x=Hypoallergene.hond,y=log.hair.ug.g , var.equal=T)
Hypoallergene.hond
# voer de t-toets voor onafhankelijke groepen uit
t.test( x=Hypoallergene.hond==Normal,y=log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( x=Hypoallergene.hond=="Normal",y=log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test( y=Hypoallergene.hond=="Normal",x=log.hair.ug.g , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond, , var.equal=T)
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond,  var.equal=T, alternative ="two.sided")
# voer de t-toets voor onafhankelijke groepen uit
t.test(log.hair.ug.g ~ Hypoallergene.hond,  var.equal=T, alternative ="less")
plumber::plumb(file='src/R/TutorialAlgorithm.R')$run()
plumber::plumb(file='src/R/TutorialAlgorithm.R')$run()
get.data("http://host.docker.internal:3030/datasetA/query")
plumber::plumb(file='src/R/TutorialAlgorithm.R')$run()
