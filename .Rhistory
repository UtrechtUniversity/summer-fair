summary(fit)
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
mock<- data.frame(x1 = c(1:10),
x2 = runif(10,0,10),
x3 = runif(10,0,10),
x4 = runif(10,0,1))
mock$y <- rnorm(10)+0.5 * mock$x1 + 2.5*mock$x2
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
detach(mock)
mock$y <- rnorm(10,0,.5)+0.5 * mock$x1 + 2.5*mock$x2
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
detach(mock)
mock$y <- rnorm(10,0,.1)+0.5 * mock$x1 + 2.5*mock$x2
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
detach(mock)
detach(mock)
detach(mock)
detach(mock)
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
detach(mock)
mock$y <- rnorm(10,0,.5)+0.5 * mock$x1 + 2.5*mock$x2
attach(mock)
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
detach(mock)
#drop variable x4
fit <- glm(y ~x1+x2+x3, data = mock)
summary(fit)
drop1(fit)
#drop variable x3
fit <- glm(y ~x1+x2, data = mock)
summary(fit)
drop1(fit)
mock<- data.frame(x1 = c(1:10),
x2 = runif(10,0,10),
x3 = runif(10,0,1),
x4 = runif(10,0,1))
mock$y <- rnorm(10,0,.5)+0.5 * mock$x1 + 2.5*mock$x2
attach(mock)
#full model
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
#drop variable x4
fit <- glm(y ~x1+x2+x3, data = mock)
summary(fit)
drop1(fit)
#drop variable x3
fit <- glm(y ~x1+x2, data = mock)
summary(fit)
drop1(fit)
mock$y <- rnorm(10,0,.25)+0.5 * mock$x1 + 2.5*mock$x2
detach(mock)
detach(mock)
#full model
fit <- glm(y ~x1+x2+x3+x4, data = mock)
summary(fit)
drop1(fit)
#drop variable x4
fit <- glm(y ~x1+x2+x3, data = mock)
summary(fit)
drop1(fit)
#drop variable x3
fit <- glm(y ~x1+x2, data = mock)
summary(fit)
drop1(fit)
## First specify the packages of interest -> needs to be in the docker for installation but here only library
packages = c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
#Elena tests if sourcing is possible
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
##use query to create data####
endpoint <- "http://localhost:3030/datasetA"
get.data <- function(endpoint){
sparql <- "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix : <http://www.semanticweb.org/trans_experiment#>
Prefix om: <http://www.ontology-of-units-of-measure.org/resource/om-2/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX tr: <http://www.thomsonreuters.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
SELECT ?round ?ex_day ?group ?level1 ?level2 ?level3 ?host_id ?treatment ?innoculationStatus ?sample_measure ?sample_result ?pathogen_name WHERE {
?experiment a :Experiment;
:experimentDay ?ex_day;
:hasMeasurement ?measurement.
optional {?experiment :repetition ?round;}
?measurement a :Measurement;
:hasHost ?host;
:hasSample ?sample.
?host :id ?host_id;
:treatment ?treatment;
:innoculationStatus ?innoculationStatus;
:locatedIn ?env.
?env  :groupNumber ?group.
optional{?env :level1 ?level1;}
optional{?env :level2 ?level2;}
optional{?env :level3 ?level3;}
optional{ ?measurement :experimentHour ?ex_hour. }
optional{ ?measurement
:hasQuantity ?quantity.
?quantity om:hasValue ?measure.
?measure om:hasNumericalValue ?sample_measure.
}
optional{ ?sample  :hasPathogen ?pathogen.
?pathogen :name ?pathogen_name }
optional {?sample :hasResult ?sample_result.}
} "
return(SPARQL(url = endpoint,query=sparql)$results)
}
#
#do data set 1
if(exists("usedata")){rm(usedata)};usedata<- get.data(endpoint)
#correct spelling
usedata <- rename(usedata,"inoculationStatus" = "innoculationStatus" )
head(usedata)
#####################################
# Process data for analysis
#####################################
#set times to the correct resolution ####
usedata$times <- setTimes(usedata,
resolution = "day",
decimals =1)
## apply rule to determine infection states to this data set ####
datawithrule <-applyRule(usedata,          #data
rule = rule.sinceany.cutoff,     #rule to apply
var.id = c("sample_measure"),    #variables with output of tests
cutoff = 0)                      #specific parameters for this rule.
## visualize data after applying rules ####
ggplot(data = datawithrule)+
geom_raster(aes(x = times,y = host_id, fill = factor(sir)))
ggplot(data = datawithrule)+
geom_path(aes(x = times,y = log10(as.numeric(sample_measure)+1), colour = factor(host_id)))+
theme(legend.position = "none")
unique(datawithrule$times)
unique(datawithrule$sample_measure)
unique(datawithrule$sir)
##arrange data for analysis ####
if(exists("data.arranged")) {rm(data.arranged)}
data.arranged <- arrangeData(data = usedata,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
covariates = c("ex_day"))
input = data.frame(data.arranged%>%
filter(i > 0 & s>0))
#fit the input data directly
fit.real <- glm(cbind(cases, s - cases) ~ 1 ,
family = binomial(link = "cloglog"),
offset = log(i/n)*dt,
data = input)
summary(fit.real)
#fit the analyseTransmission function
fit <- analyseTransmission(inputdata = usedata,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
preventError = TRUE)
#check
fit$coefficients ==fit.real$coefficients
fit$aic == fit.real$aic
fit$residuals == fit.real$residuals
#source the query function
source("src/R/Query.r")
#get data
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataC<- get.data("http://localhost:3030/datasetC")
#correct spelling
dataA <- rename(dataA,"inoculationStatus" = "innoculationStatus" )
dataB <- rename(dataB,"inoculationStatus" = "innoculationStatus" )
dataC <- rename(dataC,"inoculationStatus" = "innoculationStatus" )
#run analysis over each data set
localA <- analyseTransmission(inputdata = dataA,
rule = rule.sinceany.cutoff,
var.id = c("sample_measure"),
method = "glm",
cutoff = 0,
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "0")
localB<- analyseTransmission(inputdata = dataB,
rule = rule.sinceany.recode,
var.id = c("sample_result"),
method = "glm",
codesposnegmiss = c("+","-","NA"),
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "")
localC<- analyseTransmission(inputdata = dataC,
rule = rule.sinceany.cutoff,
var.id = c("sample_result"),
method = "glm",
cutoff = 0,
preventError = TRUE,
covars = "treatment",
reference = "control",
control = "")
#perform meta-analysis
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/GlobalAlgorithm.R", echo=TRUE)
#perform meta-analysis
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
summary(metaana)
forest.meta(metaana)
funnel.meta(metaana,studlab=TRUE,contour = c(0.9, 0.95, 0.99))
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
combine.estimates
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/LocalAlgorithm.R", echo=TRUE)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataA
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
dataB<- get.data("http://localhost:3030/datasetB")
source("src/R/Query.r")                    #Query function
get.data
"http://localhost:3030/datasetA"
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
##use query to create data####
endpoint <- "http://localhost:3030/datasetA"
get.data <- function(endpoint){
sparql <- "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix : <http://www.semanticweb.org/trans_experiment#>
Prefix om: <http://www.ontology-of-units-of-measure.org/resource/om-2/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX tr: <http://www.thomsonreuters.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
SELECT ?round ?ex_day ?group ?level1 ?level2 ?level3 ?host_id ?treatment ?innoculationStatus ?sample_measure ?sample_result ?pathogen_name WHERE {
?experiment a :Experiment;
:experimentDay ?ex_day;
:hasMeasurement ?measurement.
optional {?experiment :repetition ?round;}
?measurement a :Measurement;
:hasHost ?host;
:hasSample ?sample.
?host :id ?host_id;
:treatment ?treatment;
:innoculationStatus ?innoculationStatus;
:locatedIn ?env.
?env  :groupNumber ?group.
optional{?env :level1 ?level1;}
optional{?env :level2 ?level2;}
optional{?env :level3 ?level3;}
optional{ ?measurement :experimentHour ?ex_hour. }
optional{ ?measurement
:hasQuantity ?quantity.
?quantity om:hasValue ?measure.
?measure om:hasNumericalValue ?sample_measure.
}
optional{ ?sample  :hasPathogen ?pathogen.
?pathogen :name ?pathogen_name }
optional {?sample :hasResult ?sample_result.}
} "
return(SPARQL(url = endpoint,query=sparql)$results)
}
#
#do data set 1
if(exists("usedata")){rm(usedata)};usedata<- get.data(endpoint)
view(usedata)
get.data <- function(endpoint){
sparql <- "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
Prefix : <http://www.semanticweb.org/trans_experiment#>
Prefix om: <http://www.ontology-of-units-of-measure.org/resource/om-2/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX tr: <http://www.thomsonreuters.com/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
SELECT ?round ?ex_day ?inoculationHour ?group ?level1 ?level2 ?level3 ?host_id ?treatment ?inoculationStatus ?sample_measure ?sample_result ?sample_type ?pathogen_name WHERE {
?experiment a :Experiment;
:experimentDay ?ex_day;
:hasMeasurement ?measurement.
optional {?experiment :repetition ?round;}
?measurement a :Measurement;
:hasHost ?host;
:hasSample ?sample.
?host :id ?host_id;
:treatment ?treatment;
:inoculationStatus ?inoculationStatus;
:locatedIn ?env.
?env  :groupNumber ?group.
optional{?experiment :hasInoculation ?inoculation.
?inoculation :involves ?host.
?inoculation	 :experimentHour ?inoculationHour.}
optional{?env :level1 ?level1.}
optional{?env :level2 ?level2;}
optional{?env :level3 ?level3;}
optional{ ?measurement :experimentHour ?ex_hour. }
optional{ ?measurement
:hasQuantity ?quantity.
?quantity om:hasValue ?measure.
?measure om:hasNumericalValue ?sample_measure.
}
?sample :hasType ?sample_type.
optional{?sample  :hasPathogen ?pathogen.
?pathogen :name ?pathogen_name }
optional {?sample :hasResult ?sample_result.}
}"
return(SPARQL(url = endpoint,query=sparql)$results)
}
usedata<- get.data(endpoint)
usedata
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
dataA
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/Query.R", echo=TRUE)
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/Query.R", echo=TRUE)
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataB<- get.data("http://localhost:3030/datasetB")
#run local algorithm for each data set ####
#run analysis over data set A
localA <- analyseTransmission(inputdata = dataA,           #data set
rule = rule.sinceany.cutoff, #rule to determine infection status
var.id = c("sample_measure"),#variable defining infection status
method = "glm",              #estimation method
cutoff = 0,                  #cutoff value for infection status
preventError = TRUE,         #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",        #co variants
reference = "control",       #reference category for multivariable estimation
control = "0")               #value of control treatment
#run analysis over data set B
localB<- analyseTransmission(inputdata = dataB,            #data set
rule = rule.sinceany.recode,  #rule to determine infection status
var.id = c("sample_result"),  #variable defining infection status
method = "glm",               #estimation method
codesposnegmiss = c("+","-","NA"), #values determining infection status pos, neg of missing
preventError = TRUE,          #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",         #co variants
reference = "control",        #reference category for multivariable estimation
control = "")                 #value of control treatment
localB
localA
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB,localC),
select.treatment = "control")
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/GlobalAlgorithm.R", echo=TRUE)
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
print(metaana)
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates(list(localA,localB),
select.treatment = "control")
#combine.estimates of glm's
combine.estimates.glm <- function(local.output,
select.treatment = "All"){
#get the means and standard errors
estimates = NULL;
for(i in c(1:length(local.output)))      {
estimates <- rbind(estimates,
cbind(data.frame(mean = summary(local.output[[i]])$coefficients[,1],
se  = summary(local.output[[i]])$coefficients[,2],
treatment = names(summary(local.output[[i]])$coefficients[,1])),
study = i))
}
if(select.treatment == "reference" | select.treatment == "control" )
estimates <- estimates%>%filter(treatment == "(Intercept)")
else if(treatment!= "All")
estimates <- estimates%>%filter(treatment == select.treatment)
#simply only use the intercepts
metaout<- metagen(TE =  estimates$mean,
seTE = estimates$se,
studlab = estimates$study,
subgroup = estimates$treatment,
fixed = FALSE)
return(metaout)
}
#combine estimates with standard meta-analysis techniques ####
metaana <- combine.estimates.glm(list(localA,localB),
select.treatment = "control")
print(metaana)
forest.meta(metaana)
funnel.meta(metaana,studlab=TRUE,contour = c(0.9, 0.95, 0.99))
forest.meta(metaana)
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
dataA
dataB<- get.data("http://localhost:3030/datasetB")
dataB$sample_measure
dataB$sample_result
dataB$sample_measure
dataA$sample_measure
dataA$treatment
dataB$treatment
source("C:/Surfdrive/Projecten/SUMMERFAIR/ProjectShareSUMMERFAIR/Syntax/summer-fair/src/R/TutorialAlgorithms.R", echo=TRUE)
dataA
dataB
#load required packages (install if required)####
lapply(
c("ggplot2",
"tidyverse",
"rje",
"readxl",
"magrittr"),
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
# source required R scripts  ####
# scripts should be in subfolder "src/R"
source("src/R/DataManipulationRules.R")    #Data manipulation rules are pre- or user defined
source("src/R/LocalAlgorithm.R")           #Estimation methods
source("src/R/Query.r")                    #Query function
# get data ####
dataA<- get.data("http://localhost:3030/datasetA")
typeof(dataA$sample_measure)
#run local algorithm for each data set ####
#run analysis over data set A
localA <- analyseTransmission(inputdata = dataA,           #data set
rule = rule.sinceany.cutoff, #rule to determine infection status
var.id = c("sample_measure"),#variable defining infection status
method = "glm",              #estimation method
cutoff = 0,                  #cutoff value for infection status
preventError = TRUE,         #TRUE = remove entries with > 1 case but FOI = 0
covars = "treatment",        #co variates
reference = "control",       #reference category for multivariable estimation
control = "0")               #value of control treatment
localA
localA
dataA
head(dataA)
dataA$sample_measure
